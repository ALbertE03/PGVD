# Gu√≠a: Agregar Nuevos An√°lisis Gen√©ticos

## üìã Tabla de Contenidos
1. [Arquitectura del Sistema](#arquitectura-del-sistema)
2. [Agregar An√°lisis desde Datos en Streaming](#agregar-an√°lisis-desde-datos-en-streaming)
3. [Calcular An√°lisis desde HDFS (Datos Hist√≥ricos)](#calcular-an√°lisis-desde-hdfs)
4. [Integraci√≥n Dashboard](#integraci√≥n-dashboard)

---

## üèóÔ∏è Arquitectura del Sistema

### Flujo de Datos
```
Producer ‚Üí Kafka ‚Üí Spark Consumer ‚Üí Dashboard Flask
                          ‚Üì
                        HDFS (persistencia)
```

### Componentes Clave
- **Producer** (`producer/`): Genera datos gen√©ticos sint√©ticos y los env√≠a a Kafka
- **Spark Consumer** (`cosumer/spark_consumer.py`): Procesa streams de Kafka y ejecuta an√°lisis
- **Dashboard** (`cosumer/dashboard/`): Visualiza m√©tricas en tiempo real
- **HDFS**: Almacena todos los datos procesados para an√°lisis hist√≥rico

---

## ‚ú® Agregar An√°lisis desde Datos en Streaming

### Paso 1: Crear Funci√≥n de An√°lisis en `spark_consumer.py`

```python
def calculate_mi_nuevo_analisis(df, member_type):
    """
    Calcula un nuevo an√°lisis gen√©tico
    
    Args:
        df: DataFrame con columnas [rsid, chromosome, position, genotype, person_id, family_id]
        member_type: 'fathers', 'mothers', o 'children'
    
    Returns:
        dict con resultados del an√°lisis
    """
    try:
        # Ejemplo: Calcular distribuci√≥n de variantes por tipo
        result = df.groupBy('genotype').count().collect()
        
        data = {
            member_type: {row['genotype']: row['count'] for row in result}
        }
        
        # Enviar al dashboard
        send_to_dashboard({
            'message_type': 'MI_NUEVO_ANALISIS',
            'member_type': member_type,
            'data': data,
            'timestamp': datetime.now().isoformat()
        })
        
        print(f"‚úÖ Mi Nuevo An√°lisis calculado para {member_type}")
        return data
        
    except Exception as e:
        print(f"‚ùå Error en mi_nuevo_analisis: {str(e)}")
        return {}
```

### Paso 2: Integrar en el Pipeline de Procesamiento

Agregar la funci√≥n al ThreadPoolExecutor en `process_batch_with_genetics()`:

```python
def process_batch_with_genetics(batch_df, batch_id, member_type):
    """Procesa batch gen√©rico con an√°lisis gen√©ticos paralelos"""
    calculate_and_send_metrics(batch_df, batch_id, member_type)
    
    cached_df = batch_df.cache()
    
    with ThreadPoolExecutor(max_workers=7) as executor:  # Aumentar workers si necesario
        analysis_functions = [
            calculate_chromosome_distribution,
            calculate_position_hotspots,
            calculate_genotype_trends,
            calculate_population_heterozygosity,
            calculate_individual_heterozygosity,
            calculate_mi_nuevo_analisis  # ‚Üê AGREGAR AQU√ç
        ]
        
        futures = [executor.submit(func, cached_df, member_type) 
                   for func in analysis_functions]
        
        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                print(f"Error en an√°lisis: {str(e)}")
    
    cached_df.unpersist()
```

### Paso 3: Agregar Estructura de Datos en `dashboard_advanced.py`

```python
metrics_data = {
    # ... estructuras existentes ...
    
    'mi_nuevo_analisis': {
        'fathers': {},
        'mothers': {},
        'children': {}
    }
}
```

### Paso 4: Crear Handler en `dashboard_advanced.py`

```python
@app.route('/api/metrics', methods=['POST'])
def receive_metrics():
    # ... c√≥digo existente ...
    
    if message_type == 'MI_NUEVO_ANALISIS':
        with metrics_lock:
            member_type = data.get('member_type')
            analisis_data = data.get('data', {})
            metrics_data['mi_nuevo_analisis'][member_type] = analisis_data
            metrics_data['last_update'] = datetime.now()
        return jsonify({'status': 'success'})
```

### Paso 5: Exponer en API

```python
@app.route('/api/genetic_analysis')
def genetic_analysis():
    with metrics_lock:
        return jsonify({
            # ... datos existentes ...
            'mi_nuevo_analisis': metrics_data['mi_nuevo_analisis']
        })
```

### Paso 6: Visualizar en Frontend (`dashboard.js`)

```javascript
// Crear gr√°fica
const miNuevoChart = new Chart(ctx, {
    type: 'bar',
    data: {
        labels: [],
        datasets: [{
            label: 'Mi Nuevo An√°lisis',
            data: [],
            backgroundColor: 'rgba(139, 92, 246, 0.8)'
        }]
    },
    options: commonChartOptions
});

// Actualizar con datos
function updateMiNuevoAnalisis(data) {
    const analisis = data.mi_nuevo_analisis || {};
    const labels = Object.keys(analisis.fathers || {});
    const datasets = [
        {
            label: 'Fathers',
            data: labels.map(k => analisis.fathers[k] || 0),
            backgroundColor: '#3b82f6'
        },
        {
            label: 'Mothers', 
            data: labels.map(k => analisis.mothers[k] || 0),
            backgroundColor: '#ef4444'
        },
        {
            label: 'Children',
            data: labels.map(k => analisis.children[k] || 0),
            backgroundColor: '#10b981'
        }
    ];
    
    updateBarChart(miNuevoChart, labels, datasets);
}

// Llamar en updateDashboard()
async function updateDashboard() {
    const response = await fetch('/api/genetic_analysis');
    const data = await response.json();
    updateMiNuevoAnalisis(data);
    // ... otras actualizaciones ...
}
```

---

## üìä Calcular An√°lisis desde HDFS (Datos Hist√≥ricos)

### Opci√≥n 1: Script de An√°lisis Batch Independiente

Crear `cosumer/batch_analysis.py`:

```python
from pyspark.sql import SparkSession
from datetime import datetime
import requests

def analyze_historical_data():
    """
    Analiza TODOS los datos guardados en HDFS desde el inicio
    """
    spark = SparkSession.builder \
        .appName("Historical Genetic Analysis") \
        .master("spark://spark-master:7077") \
        .config("spark.hadoop.fs.defaultFS", "hdfs://namenode:9000") \
        .getOrCreate()
    
    # Leer TODOS los datos desde HDFS
    hdfs_paths = [
        "hdfs://namenode:9000/data/fathers",
        "hdfs://namenode:9000/data/mothers", 
        "hdfs://namenode:9000/data/children"
    ]
    
    for path, member_type in zip(hdfs_paths, ['fathers', 'mothers', 'children']):
        print(f"\n{'='*50}")
        print(f"Analizando datos hist√≥ricos de {member_type.upper()}")
        print(f"{'='*50}\n")
        
        try:
            # Leer todos los parquet guardados
            df = spark.read.parquet(path)
            total_records = df.count()
            print(f"üì¶ Total registros en HDFS: {total_records:,}")
            
            # EJEMPLO: An√°lisis de variantes raras
            rare_variants = df.groupBy('rsid') \
                .count() \
                .filter('count = 1') \
                .count()
            
            rare_pct = (rare_variants / total_records * 100) if total_records > 0 else 0
            
            print(f"üî¨ Variantes raras (√∫nicas): {rare_variants:,} ({rare_pct:.2f}%)")
            
            # EJEMPLO: Distribuci√≥n cromos√≥mica completa
            chrom_dist = df.groupBy('chromosome').count().collect()
            print(f"\nüìä Distribuci√≥n Cromos√≥mica Hist√≥rica:")
            for row in sorted(chrom_dist, key=lambda x: x['count'], reverse=True)[:5]:
                print(f"   Chr {row['chromosome']}: {row['count']:,} variantes")
            
            # EJEMPLO: An√°lisis de familia m√°s estudiada
            family_stats = df.groupBy('family_id').count().collect()
            if family_stats:
                top_family = max(family_stats, key=lambda x: x['count'])
                print(f"\nüë®‚Äçüë©‚Äçüëß‚Äçüë¶ Familia m√°s estudiada: {top_family['family_id']} "
                      f"({top_family['count']:,} variantes)")
            
            # Enviar resultados al dashboard
            send_historical_results({
                'member_type': member_type,
                'total_records': total_records,
                'rare_variants': rare_variants,
                'rare_percentage': rare_pct,
                'chromosome_distribution': {
                    row['chromosome']: row['count'] for row in chrom_dist
                },
                'analysis_timestamp': datetime.now().isoformat()
            })
            
        except Exception as e:
            print(f"‚ùå Error procesando {member_type}: {str(e)}")
    
    spark.stop()
    print("\n‚úÖ An√°lisis hist√≥rico completado")

def send_historical_results(data):
    """Env√≠a resultados al dashboard Flask"""
    try:
        response = requests.post(
            'http://dashboard:8080/api/historical_analysis',
            json={
                'message_type': 'HISTORICAL_ANALYSIS',
                'data': data
            },
            timeout=5
        )
        if response.ok:
            print(f"   ‚Üí Resultados enviados al dashboard")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  No se pudo enviar al dashboard: {str(e)}")

if __name__ == '__main__':
    analyze_historical_data()
```

### Ejecutar el An√°lisis Hist√≥rico

```bash
# Desde el contenedor de Spark
docker exec -it spark-master bash

# Instalar requests si no est√°
pip install requests

# Ejecutar an√°lisis
spark-submit \
    --master spark://spark-master:7077 \
    --deploy-mode client \
    /app/batch_analysis.py
```

### Opci√≥n 2: Integrar en Spark Consumer con Flag

Modificar `spark_consumer.py` para modo batch inicial:

```python
import os

BATCH_MODE = os.getenv('INITIAL_BATCH', 'false').lower() == 'true'

def run_initial_batch_analysis(spark):
    """
    Ejecuta an√°lisis completo de datos hist√≥ricos al inicio
    Solo se ejecuta una vez cuando INITIAL_BATCH=true
    """
    if not BATCH_MODE:
        return
    
    print("\n" + "="*70)
    print("üîÑ MODO BATCH INICIAL: Analizando datos hist√≥ricos desde HDFS")
    print("="*70 + "\n")
    
    hdfs_paths = {
        'fathers': 'hdfs://namenode:9000/data/fathers',
        'mothers': 'hdfs://namenode:9000/data/mothers',
        'children': 'hdfs://namenode:9000/data/children'
    }
    
    for member_type, path in hdfs_paths.items():
        try:
            df = spark.read.parquet(path)
            
            # Ejecutar TODOS los an√°lisis sobre datos hist√≥ricos
            calculate_chromosome_distribution(df, member_type)
            calculate_position_hotspots(df, member_type)
            calculate_genotype_trends(df, member_type)
            calculate_population_heterozygosity(df, member_type)
            calculate_individual_heterozygosity(df, member_type)
            
            print(f"‚úÖ An√°lisis hist√≥rico completado para {member_type}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  No hay datos hist√≥ricos para {member_type}: {str(e)}")
    
    print("\n‚úÖ An√°lisis batch inicial completado, iniciando streaming...\n")

# En main():
if __name__ == "__main__":
    spark = create_spark_session()
    
    # Ejecutar an√°lisis hist√≥rico al inicio
    run_initial_batch_analysis(spark)
    
    # Luego iniciar streaming normal
    process_kafka_stream(spark)
```

### Activar Modo Batch en docker-compose.yml

```yaml
services:
  spark-driver:
    environment:
      - INITIAL_BATCH=true  # ‚Üê Agregar esta l√≠nea
```

---

## üé® Integraci√≥n Dashboard

### Agregar Endpoint para Datos Hist√≥ricos

```python
# dashboard_advanced.py

metrics_data['historical_analysis'] = {}

@app.route('/api/historical_analysis', methods=['POST'])
def receive_historical_analysis():
    """Recibe resultados de an√°lisis hist√≥rico"""
    data = request.json
    member_type = data.get('data', {}).get('member_type')
    
    with metrics_lock:
        metrics_data['historical_analysis'][member_type] = data.get('data', {})
        metrics_data['last_update'] = datetime.now()
    
    print(f"üìä Datos hist√≥ricos recibidos para {member_type}")
    return jsonify({'status': 'success'})

@app.route('/api/historical_analysis', methods=['GET'])
def get_historical_analysis():
    """Devuelve an√°lisis hist√≥rico calculado"""
    with metrics_lock:
        return jsonify(metrics_data['historical_analysis'])
```

### Visualizar en Frontend

```javascript
// dashboard.js

async function loadHistoricalData() {
    try {
        const response = await fetch('/api/historical_analysis');
        const data = await response.json();
        
        if (Object.keys(data).length === 0) {
            console.log('No hay datos hist√≥ricos disponibles');
            return;
        }
        
        // Mostrar estad√≠sticas hist√≥ricas
        displayHistoricalStats(data);
        
    } catch (error) {
        console.error('Error cargando datos hist√≥ricos:', error);
    }
}

function displayHistoricalStats(data) {
    const container = document.getElementById('historical-stats');
    
    let html = '<div class="historical-summary">';
    html += '<h3>üìä An√°lisis Hist√≥rico Completo (HDFS)</h3>';
    
    for (const [memberType, stats] of Object.entries(data)) {
        html += `
            <div class="stat-card">
                <h4>${memberType.toUpperCase()}</h4>
                <p>Total Registros: ${stats.total_records?.toLocaleString()}</p>
                <p>Variantes Raras: ${stats.rare_variants?.toLocaleString()} (${stats.rare_percentage?.toFixed(2)}%)</p>
                <p>An√°lisis: ${new Date(stats.analysis_timestamp).toLocaleString()}</p>
            </div>
        `;
    }
    
    html += '</div>';
    container.innerHTML = html;
}

// Cargar al inicio
document.addEventListener('DOMContentLoaded', () => {
    loadHistoricalData();
    setInterval(updateDashboard, 2000);
});
```

---

## üöÄ Checklist Completo

### Para Nuevo An√°lisis en Streaming:
- [ ] Crear funci√≥n `calculate_mi_analisis()` en `spark_consumer.py`
- [ ] Agregar funci√≥n a `process_batch_with_genetics()`
- [ ] Agregar estructura de datos en `metrics_data` (dashboard)
- [ ] Crear handler POST en `/api/metrics`
- [ ] Exponer datos en `/api/genetic_analysis`
- [ ] Crear gr√°fica en `dashboard.js`
- [ ] Agregar actualizaci√≥n en `updateDashboard()`

### Para An√°lisis Hist√≥rico (HDFS):
- [ ] Crear `batch_analysis.py` o flag `INITIAL_BATCH`
- [ ] Leer datos con `spark.read.parquet(hdfs_path)`
- [ ] Ejecutar an√°lisis sobre DataFrame completo
- [ ] Crear endpoint `/api/historical_analysis` (POST + GET)
- [ ] Agregar visualizaci√≥n en dashboard
- [ ] Ejecutar con `spark-submit` o al inicio del consumer

---

## üí° Ejemplos de An√°lisis √ötiles

### 1. Detecci√≥n de Consanguinidad
```python
def calculate_consanguinity(df, member_type):
    """Detecta homocigosidad elevada que puede indicar consanguinidad"""
    family_stats = df.groupBy('family_id') \
        .agg(
            F.count('*').alias('total_snps'),
            F.sum(F.when(F.col('genotype').rlike(r'^([ACGT])\1$'), 1).otherwise(0)).alias('homozygous')
        ) \
        .withColumn('homozygosity_rate', F.col('homozygous') / F.col('total_snps'))
    
    # Familias con >75% homocigosidad (posible consanguinidad)
    high_consanguinity = family_stats.filter('homozygosity_rate > 0.75').collect()
    
    return {
        'high_risk_families': [row['family_id'] for row in high_consanguinity],
        'homozygosity_rates': {row['family_id']: row['homozygosity_rate'] 
                               for row in family_stats.collect()}
    }
```

### 2. Identificaci√≥n de Variantes Patog√©nicas
```python
def identify_pathogenic_variants(df, member_type):
    """Busca patrones asociados a enfermedades conocidas"""
    # Ejemplo: Variantes en BRCA1 (cromosoma 17)
    brca1_variants = df.filter(
        (F.col('chromosome') == '17') & 
        (F.col('position').between(43044295, 43125483))
    ).select('family_id', 'person_id', 'rsid', 'genotype').collect()
    
    return {
        'brca1_carriers': len(brca1_variants),
        'affected_families': list(set(row['family_id'] for row in brca1_variants))
    }
```

### 3. An√°lisis de Heredabilidad
```python
def calculate_heritability(df_children, df_parents):
    """Calcula qu√© variantes son heredadas vs de novo"""
    # Join children con padres por family_id
    inherited = df_children.alias('c').join(
        df_parents.alias('p'),
        (F.col('c.family_id') == F.col('p.family_id')) &
        (F.col('c.rsid') == F.col('p.rsid')) &
        (F.col('c.genotype') == F.col('p.genotype'))
    ).count()
    
    total_child_variants = df_children.count()
    de_novo = total_child_variants - inherited
    
    return {
        'inherited_variants': inherited,
        'de_novo_variants': de_novo,
        'heritability_rate': inherited / total_child_variants if total_child_variants > 0 else 0
    }
```

---

## üìù Notas Importantes

1. **Performance**: Cachear DataFrames grandes con `.cache()` antes de m√∫ltiples operaciones
2. **HDFS Paths**: Verificar que las rutas sean correctas: `hdfs://namenode:9000/data/`
3. **Thread Safety**: Usar `metrics_lock` al modificar `metrics_data` en dashboard
4. **Memoria**: Aumentar `spark.executor.memory` si procesas datasets muy grandes
5. **Testing**: Probar an√°lisis con subset peque√±o antes de aplicar a todos los datos

---

## üîß Troubleshooting

### Error: "Path does not exist: hdfs://..."
```bash
# Verificar contenido de HDFS
docker exec -it namenode bash
hdfs dfs -ls /data/
```

### Error: "OutOfMemoryError"
```python
# Procesar en chunks
df.repartition(100).cache()  # Distribuir en m√°s particiones
```

### Dashboard no recibe datos
```bash
# Verificar conectividad
docker exec -it spark-driver curl http://dashboard:8080/health
```

---

## ‚úÖ Conclusi√≥n

Con esta gu√≠a puedes:
1. ‚úÖ Agregar nuevos an√°lisis gen√©ticos al pipeline de streaming
2. ‚úÖ Calcular an√°lisis sobre TODOS los datos hist√≥ricos en HDFS
3. ‚úÖ Integrar resultados en el dashboard en tiempo real
4. ‚úÖ Mantener c√≥digo limpio y performante

**¬°Listo para agregar an√°lisis personalizados!** üß¨üöÄ
