# ğŸ§¬ Sistema de AnÃ¡lisis GenÃ³mico - HDFS + Spark + Gradio

Sistema completo de procesamiento y anÃ¡lisis de datos genÃ³micos utilizando Big Data technologies.

## ğŸ“‹ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer  â”‚ â”€â”€â”€> â”‚  Kafka   â”‚ â”€â”€â”€> â”‚ HDFS Loader â”‚ â”€â”€â”€> â”‚     HDFS      â”‚
â”‚  (Genomas)  â”‚      â”‚ Topics   â”‚      â”‚  (Parquet)  â”‚      â”‚ (Distributed) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                      â”‚
                                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard  â”‚ <â”€â”€â”€ â”‚  Spark   â”‚ <â”€â”€â”€ â”‚    YARN     â”‚ <â”€â”€â”€ â”‚   Analytics   â”‚
â”‚   (Gradio)  â”‚      â”‚ Jobs/SQL â”‚      â”‚  Resource   â”‚      â”‚   & Queries   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Componentes

### 1. **Producer** - Generador de Datos GenÃ³micos
- Genera familias con datos de padres, madres e hijos
- Publica a Kafka en topics separados
- 3 productores en paralelo (escalable)

### 2. **HDFS** - Almacenamiento Distribuido
- **NameNode**: GestiÃ³n de metadatos (puerto 9870)
- **DataNodes** (3): Almacenamiento distribuido
- Datos en formato **Parquet** (comprimido y columnar)

### 3. **YARN** - GestiÃ³n de Recursos
- **ResourceManager**: OrquestaciÃ³n de recursos (puerto 8088)
- **NodeManagers** (2): EjecuciÃ³n de tareas
- **HistoryServer**: Historial de jobs (puerto 8188)

### 4. **Spark** - Procesamiento Distribuido
- **Master**: Coordinador (puerto 8080, 7077)
- **Workers** (2): Ejecutores de tareas
- AnÃ¡lisis paralelo de genomas

### 5. **HDFS Loader**
- Consume datos de Kafka
- Escribe batches en HDFS como Parquet
- Buffer de 10,000 registros

### 6. **Dashboard Gradio**
- Interfaz web interactiva (puerto 7860)
- GrÃ¡ficos con Plotly
- Jobs Spark desde UI

## ğŸ“¦ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos
- Docker & Docker Compose
- 8 GB RAM mÃ­nimo (16 GB recomendado)
- 20 GB espacio en disco

### Paso 1: Levantar Producer (Kafka + ZooKeeper)

```bash
cd producer
docker-compose up --scale genomic-producer=3 --build -d
```

Esto levanta:
- âœ… Kafka (puerto 9092)
- âœ… ZooKeeper (puerto 2181)
- âœ… 3 Productores genÃ³micos

### Paso 2: Levantar Consumer (HDFS + YARN + Spark + Dashboard)

```bash
cd cosumer
docker-compose up --build -d
```

Esto levanta:
- âœ… HDFS NameNode + 3 DataNodes
- âœ… YARN ResourceManager + 2 NodeManagers
- âœ… Spark Master + 2 Workers
- âœ… HDFS Loader (consume Kafka â†’ HDFS)
- âœ… Dashboard Gradio

### Paso 3: Verificar que todo estÃ¡ funcionando

```bash
# Ver logs del consumer
docker-compose -f cosumer/docker-compose.yml logs -f genomic-consumer

# Ver logs del producer
docker-compose -f producer/docker-compose.yml logs -f genomic-producer
```

## ğŸŒ URLs de Acceso

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **Dashboard Gradio** | http://localhost:7860 | Interfaz principal de anÃ¡lisis |
| **Spark Master UI** | http://localhost:8080 | Estado del cluster Spark |
| **HDFS NameNode** | http://localhost:9870 | Explorador de archivos HDFS |
| **YARN ResourceManager** | http://localhost:8088 | GestiÃ³n de recursos YARN |
| **History Server** | http://localhost:8188 | Historial de jobs MapReduce |

## ğŸ“Š Uso del Dashboard

### Tab 1: ğŸ  Overview
- **Selecciona tipo de miembro**: Padres / Madres / Hijos
- **Ajusta lÃ­mite de datos**: Cantidad de SNPs a cargar
- **Click "Cargar Datos"**: Visualiza distribuciones y mÃ©tricas

**GrÃ¡ficos disponibles:**
- ğŸ“Š DistribuciÃ³n de SNPs por Cromosoma
- ğŸ”¬ Top 20 Genotipos mÃ¡s Frecuentes
- ğŸŒˆ Diversidad GenÃ©tica por Cromosoma

### Tab 2: ğŸ—ºï¸ Heatmap CromosÃ³mico
- Visualiza densidad de SNPs a lo largo de regiones genÃ³micas
- Selecciona tipo de miembro y lÃ­mite de datos
- Heatmap interactivo con 50 bins por cromosoma

### Tab 3: ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ AnÃ¡lisis Familiar
- EstadÃ­sticas de familias completadas
- Promedio de hijos por familia
- Tiempos de generaciÃ³n
- CorrelaciÃ³n SNPs vs TamaÃ±o familiar

### Tab 4: âš¡ Spark Jobs
Ejecuta anÃ¡lisis masivos sobre TODOS los datos en HDFS:

1. **EstadÃ­sticas Globales**
   - Total SNPs por tipo de miembro
   - Familias Ãºnicas
   - Cromosomas y genotipos Ãºnicos

2. **AnÃ¡lisis CromosÃ³mico**
   - DistribuciÃ³n completa por cromosoma
   - Min/Max/Media de posiciones
   - Diversidad de genotipos

3. **Diversidad GenÃ©tica**
   - Ãndice de diversidad por cromosoma
   - CorrelaciÃ³n SNPs vs Genotipos

### Tab 5: â„¹ï¸ InformaciÃ³n
- ConfiguraciÃ³n del sistema
- Arquitectura completa
- Rutas en HDFS
- TecnologÃ­as utilizadas

## ğŸ”§ Comandos Ãštiles

### Verificar datos en HDFS

```bash
# Entrar al NameNode
docker exec -it namenode bash

# Listar archivos
hdfs dfs -ls /genomic_data
hdfs dfs -ls /genomic_data/fathers
hdfs dfs -ls /genomic_data/mothers
hdfs dfs -ls /genomic_data/children
hdfs dfs -ls /genomic_data/families_metadata

# Ver tamaÃ±o de datos
hdfs dfs -du -h /genomic_data
```

### Ejecutar Spark Shell

```bash
# Entrar al Spark Master
docker exec -it spark-master bash

# Lanzar Spark Shell (Scala)
spark-shell --master spark://spark-master:7077

# Lanzar PySpark (Python)
pyspark --master spark://spark-master:7077
```

### Consultar datos con Spark SQL

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("GenomicQuery") \
    .master("spark://spark-master:7077") \
    .config("spark.hadoop.fs.defaultFS", "hdfs://namenode:9000") \
    .getOrCreate()

# Leer datos
df = spark.read.parquet("hdfs://namenode:9000/genomic_data/fathers/*.parquet")

# Mostrar esquema
df.printSchema()

# Contar registros
df.count()

# Ver muestra
df.show(10)

# AnÃ¡lisis por cromosoma
df.groupBy("chromosome").count().show()
```

## ğŸ“ Estructura de Datos en HDFS

```
/genomic_data/
â”œâ”€â”€ fathers/
â”‚   â”œâ”€â”€ batch_20251019_120000_0.parquet
â”‚   â”œâ”€â”€ batch_20251019_120030_1.parquet
â”‚   â””â”€â”€ ...
â”œâ”€â”€ mothers/
â”‚   â”œâ”€â”€ batch_20251019_120000_0.parquet
â”‚   â””â”€â”€ ...
â”œâ”€â”€ children/
â”‚   â”œâ”€â”€ batch_20251019_120000_0.parquet
â”‚   â””â”€â”€ ...
â””â”€â”€ families_metadata/
    â”œâ”€â”€ family_FAM_ABC123_20251019_120000.json
    â””â”€â”€ ...
```

### Formato Parquet Schema

```
root
 |-- family_id: string
 |-- person_id: string
 |-- member_type: string
 |-- chromosome: string
 |-- position: long
 |-- genotype: string
 |-- timestamp: string
 |-- gender: string
```

## ğŸ›‘ Detener el Sistema

```bash
# Detener consumer
cd cosumer
docker-compose down

# Detener producer
cd producer
docker-compose down
```

## ğŸ”¥ Limpiar todo (incluye volÃºmenes)

```bash
# Detener y eliminar volÃºmenes del consumer
cd cosumer
docker-compose down -v

# Detener y eliminar volÃºmenes del producer
cd producer
docker-compose down -v
```

âš ï¸ **Advertencia**: Esto eliminarÃ¡ TODOS los datos almacenados en HDFS.

## ğŸ“ˆ Rendimiento y Escalabilidad

### ConfiguraciÃ³n Actual
- **Producers**: 3 instancias
- **DataNodes**: 3 nodos
- **NodeManagers**: 2 nodos
- **Spark Workers**: 2 workers (2 cores, 2GB cada uno)
- **Batch Size**: 10,000 SNPs

### Escalar Horizontalmente

#### MÃ¡s Producers
```bash
docker-compose up --scale genomic-producer=5 --build -d
```

#### MÃ¡s DataNodes (editar docker-compose.yml)
```yaml
datanode4:
  image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
  # ... configuraciÃ³n similar a datanode1
```

#### MÃ¡s Spark Workers
```yaml
spark-worker-3:
  image: bde2020/spark-worker:3.3.0-hadoop3.3
  # ... configuraciÃ³n similar a spark-worker-1
```

## ğŸ› Troubleshooting

### El dashboard no carga datos

1. Verificar que HDFS tenga datos:
```bash
docker exec -it namenode hdfs dfs -ls /genomic_data/fathers
```

2. Verificar logs del loader:
```bash
docker-compose logs -f genomic-consumer | grep "HDFS Loader"
```

### Spark Jobs fallan

1. Verificar memoria disponible en workers:
```bash
# Acceder a Spark Master UI: http://localhost:8080
```

2. Ajustar configuraciÃ³n en docker-compose.yml:
```yaml
YARN_CONF_yarn_nodemanager_resource_memory__mb=8192
SPARK_WORKER_MEMORY=4g
```

### HDFS NameNode no arranca

1. Verificar que no haya conflictos de puertos:
```bash
lsof -i :9870
lsof -i :9000
```

2. Limpiar y reiniciar:
```bash
docker-compose down -v
docker-compose up -d
```

## ğŸ“š Referencias

- [Hadoop HDFS Documentation](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Gradio Documentation](https://www.gradio.app/docs/)
- [Apache Parquet Format](https://parquet.apache.org/docs/)

## ğŸ‘¥ Autores

Proyecto acadÃ©mico de Procesamiento de Grandes VolÃºmenes de Datos

---

ğŸ§¬ **Genomic Analysis Platform** | Big Data Technologies | 2025
