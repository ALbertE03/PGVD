# PGVD - Plataforma de GeneraciÃ³n y VisualizaciÃ³n de Datos GenÃ³micos

## ğŸ“‹ DescripciÃ³n del Proyecto

Implementa una arquitectura de streaming distribuida utilizando **Kafka** como broker de mensajes, **Spark Structured Streaming** para procesamiento en tiempo real, y un dashboard interactivo para visualizaciÃ³n.

### CaracterÃ­sticas Principales
- âœ… **GeneraciÃ³n masiva de SNPs genÃ³micos** en mÃºltiples threads paralelos
- âœ… **Procesamiento distribuido en tiempo real** con Spark Structured Streaming
- âœ… **AnÃ¡lisis de variantes genÃ©ticas** por familia
- âœ… **Dashboard interactivo** para monitoreo y visualizaciÃ³n
- âœ… **Arquitectura dockerizada** para facilitar despliegue

---

## ğŸ“ Estructura del Repositorio

```
PGVD/
â”œâ”€â”€ producer/                 # Producer: Generador de datos genÃ³micos
â”‚   â”œâ”€â”€ producer.py          # Script principal de producciÃ³n
â”‚   â”œâ”€â”€ family_generator.py  # Generador de familias y SNPs
â”‚   â”œâ”€â”€ streaming_manager.py # Gestor de streaming Kafka
â”‚   â”œâ”€â”€ config.py            # ConfiguraciÃ³n del producer
â”‚   â”œâ”€â”€ family/              # Modelos de generaciÃ³n familiar
â”‚   â”‚   â”œâ”€â”€ base_generator.py
â”‚   â”‚   â”œâ”€â”€ father.py
â”‚   â”‚   â”œâ”€â”€ mother.py
â”‚   â”‚   â””â”€â”€ childs.py
â”‚   â”œâ”€â”€ models/              # Modelos de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_models.py
â”‚   â”œâ”€â”€ data/                # Datos de entrada
â”‚   â”‚   â””â”€â”€ archive-2/       # Genomas de referencia (Kaggle)
â”‚   â”œâ”€â”€ docker-compose.yml   # OrquestaciÃ³n de contenedores
â”‚   â”œâ”€â”€ Dockerfile           # Imagen del producer
â”‚   â”œâ”€â”€ requirements.txt      # Dependencias Python
â”‚   â””â”€â”€ aed.ipynb            # AnÃ¡lisis exploratorio de datos
â”‚
â”œâ”€â”€ cosumer/                 # Consumer: Procesamiento en tiempo real
â”‚   â”œâ”€â”€ spark_consumer.py    # Consumer principal con Spark Streaming
â”‚   â”œâ”€â”€ docker-compose.yml   # OrquestaciÃ³n de contenedores
â”‚   â”œâ”€â”€ dockerfile           # Imagen del consumer
â”‚   â”œâ”€â”€ requirements.txt      # Dependencias Python
â”‚   â”œâ”€â”€ requirements_dashboard.txt  # Dependencias del dashboard
â”‚   â”œâ”€â”€ dashboard/           # Dashboard web interactivo
â”‚   â”‚   â”œâ”€â”€ dashboard_advanced.py         # Backend avanzado
â”‚   â”‚   â”œâ”€â”€ dashboard_genomic_advanced.py # LÃ³gica genÃ³mica
â”‚   â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”‚   â””â”€â”€ dashboard.js
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚       â”œâ”€â”€ index.html
â”‚   â”‚       â””â”€â”€ index_advanced.html
â”‚   â”œâ”€â”€ entrypoint.sh        # Script de entrada del contenedor
â”‚   â””â”€â”€ requirements_dashboard.txt
â”‚
â”œâ”€â”€ start.sh                 # ğŸš€ Script para iniciar el proyecto completo
â”œâ”€â”€ stop.sh                  # ğŸ›‘ Script para detener el proyecto
â”œâ”€â”€ README.md                # Este archivo
â””â”€â”€ improve.md               # Mejoras futuras y notas tÃ©cnicas

Dataset de entrada: [Family Genome Dataset - Kaggle](https://www.kaggle.com/datasets/zusmani/family-genome-dataset)
```

---

## ğŸš€ Inicio RÃ¡pido

### Requisitos Previos
- **Docker** (versiÃ³n 20.10+)
- **Docker Compose** (versiÃ³n 1.29+)
- **Git**
- **Variables de entorno** configuradas en `.env.sh`

### InstalaciÃ³n y EjecuciÃ³n

#### 1ï¸âƒ£ Clonar el repositorio
```bash
git clone https://github.com/ALbertE03/PGVD.git
cd PGVD
```

#### 2ï¸âƒ£ Configurar variables de entorno
Crear archivo `.env.sh` en la raÃ­z del proyecto:
```bash
#!/bin/bash
export PRODUCER_PATH="$(dirname "$0")/producer"
export CONSUMER_PATH="$(dirname "$0")/cosumer"
export KAFKA_BROKER="kafka:9092"
export SPARK_MASTER="spark://spark-master:7077"
```

Hacer el archivo ejecutable:
```bash
chmod +x .env.sh
```

#### 3ï¸âƒ£ Ejecutar el proyecto completo

**OpciÃ³n A: Script de inicio automÃ¡tico (RECOMENDADO)**
```bash
chmod +x start.sh
./start.sh
```

**OpciÃ³n B: Ejecutar componentes manualmente**
```bash
# Terminal 1: Producer
cd producer && docker compose up --scale genomic-producer=2 -d

# Terminal 2: Consumer
cd cosumer && docker compose up -d
```

#### 4ï¸âƒ£ Acceder al Dashboard
Una vez que los servicios estÃ©n ejecutÃ¡ndose:
```
http://localhost:5000
```

#### 5ï¸âƒ£ Detener el proyecto
```bash
./stop.sh
```

---

## ğŸ“Š Componentes del Sistema

### Producer (Generador de Datos)
**UbicaciÃ³n**: `producer/`

Genera datos genÃ³micos sintÃ©ticos a partir del dataset de Kaggle. CaracterÃ­sticas:
- Crea familias (padre, madre, hijos)
- Genera SNPs (Single Nucleotide Polymorphisms)
- Produce mensajes a tÃ³pics de Kafka especializados (`fathers`, `mothers`, `children`)
- Ejecuta mÃºltiples instancias en paralelo para simular carga masiva

**Scripts de ingesta**:
- `producer.py` - Punto de entrada principal
- `family_generator.py` - LÃ³gica de generaciÃ³n de familias
- `streaming_manager.py` - Gestor de flujo a Kafka

**Archivos relacionados**:
- `family/base_generator.py` - Clase base de generaciÃ³n
- `family/father.py`, `mother.py`, `childs.py` - Modelos genÃ©ticos
- `models/data_models.py` - Esquemas y estructuras de datos

---

### Consumer (Spark Structured Streaming)
**UbicaciÃ³n**: `cosumer/`

Procesa el flujo de datos genÃ³micos en tiempo real utilizando Apache Spark. CaracterÃ­sticas:
- Lectura de Kafka en tiempo real
- Procesamiento con ventanas deslizantes (5 segundos)
- Agregaciones y anÃ¡lisis de variantes genÃ©ticas
- Almacenamiento de resultados

**Script principal**: `spark_consumer.py`

---

### Dashboard Interactivo
**UbicaciÃ³n**: `cosumer/dashboard/`

VisualizaciÃ³n web en tiempo real de los anÃ¡lisis genÃ³micos. CaracterÃ­sticas:
- GrÃ¡ficos de variantes por familia
- EstadÃ­sticas de SNPs
- Monitoreo de salud del sistema
- Interfaz responsive

**Acceso**: `http://localhost:5000`

**Versiones disponibles**:
- `dashboard.py` - VersiÃ³n estÃ¡ndar
- `dashboard_advanced.py` - VersiÃ³n avanzada con anÃ¡lisis complejos
- `dashboard_genomic_advanced.py` - AnÃ¡lisis genÃ³mico especializado

---

## ğŸ³ Docker & Docker Compose

### Estructura Docker

**Producer Stack**:
```yaml
producer/docker-compose.yml
â”œâ”€â”€ genomic-producer Ã— 2  # Instancias paralelas del generador
â”œâ”€â”€ kafka                # Broker de mensajes
â””â”€â”€ zookeeper           # Coordinador Kafka
```

**Consumer Stack**:
```yaml
cosumer/docker-compose.yml
â”œâ”€â”€ spark-master        # Coordinador Spark
â”œâ”€â”€ spark-worker        # Nodos de procesamiento distribuido
â””â”€â”€ dashboard          # Servidor Flask de visualizaciÃ³n
```

### Comandos Docker Ãštiles

**Ver logs en tiempo real**:
```bash
# Producer
cd producer && docker compose logs -f

# Consumer
cd cosumer && docker compose logs -f
```

**Listar contenedores activos**:
```bash
docker ps -a
```

**Detener servicios especÃ­ficos**:
```bash
# Producer
cd producer && docker compose down

# Consumer
cd cosumer && docker compose down
```

**Reconstruir imÃ¡genes**:
```bash
cd producer && docker compose build --no-cache
cd cosumer && docker compose build --no-cache
```

**Ver recursos utilizados**:
```bash
docker stats
```

---

## ğŸ“ˆ Pipeline de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Datos Kaggle       â”‚
â”‚ (Genomas Familiares)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Producer        â”‚
â”‚  (x2 paralelo)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka Topics      â”‚
â”‚ fathers,mothers,... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Spark Consumer     â”‚
â”‚  Streaming Analysis â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard Web      â”‚
â”‚ http://localhost:5000
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno Clave
```bash
PRODUCER_PATH="./producer"          # Ruta al directorio del producer
CONSUMER_PATH="./cosumer"           # Ruta al directorio del consumer
KAFKA_BROKER="kafka:9092"           # DirecciÃ³n del broker Kafka
SPARK_MASTER="spark://spark-master:7077"  # URL del master de Spark
```

### Archivos de ConfiguraciÃ³n
- `producer/config.py` - ParÃ¡metros del producer
- `.env.sh` - Variables de entorno globales
- `producer/docker-compose.yml` - Servicios del producer
- `cosumer/docker-compose.yml` - Servicios del consumer

---

## ğŸ“š Consultas y AnÃ¡lisis Disponibles

El sistema ejecuta anÃ¡lisis automÃ¡ticos sobre:

### 1. EstadÃ­sticas de SNPs por Familia
- Recuento total de variantes genÃ©ticas
- Frecuencia de alelos (A/T/G/C)
- Patrones de herencia familiar

### 2. AnÃ¡lisis de Variabilidad GenÃ©tica
- Diversidad genÃ³mica dentro de familias
- Correlaciones entre padres e hijos
- DetecciÃ³n de anomalÃ­as genÃ©ticas

### 3. MÃ©tricas de Rendimiento del Sistema
- Mensajes procesados por segundo
- Latencia de procesamiento (ms)
- Disponibilidad del cluster Spark

---
