# ğŸ§¬ PGVD - Genomic Data Processing with Apache Spark & Kafka

**Proyecto AcadÃ©mico de Procesamiento de Datos GenÃ³micos en Tiempo Real usando Apache Spark, Kafka y HDFS**

## ğŸ“‹ DescripciÃ³n del Proyecto

PGVD es una plataforma de **procesamiento distribuido en tiempo real** de datos genÃ³micos usando:

- **Apache Spark**: Procesamiento distribuido de datos genÃ©ticos
- **Apache Kafka**: Ingesta en tiempo real de datos desde productores
- **HDFS**: Almacenamiento distribuido de datasets
- **Flask Dashboard**: VisualizaciÃ³n avanzada con mÃ©tricas de streaming genÃ©tico
- **Docker Compose**: OrquestaciÃ³n completa de servicios

### CaracterÃ­sticas Principales

âœ… **Procesamiento de Datos GenÃ³micos**
- AnÃ¡lisis de familias (Padre, Madre, Hijos)
- DetecciÃ³n de variantes genÃ©ticas
- CÃ¡lculo de orientaciÃ³n genÃ©tica (Dominante/Recesivo/Heterocigoto)

âœ… **Streaming en Tiempo Real**
- Ingesta desde Kafka
- Ventanas de tiempo para anÃ¡lisis
- DetecciÃ³n de anomalÃ­as genÃ©ticas

âœ… **MÃ©tricas Avanzadas**
- Tasa de mutaciÃ³n en tiempo real
- DistribuciÃ³n de genotipos
- Top genes y variantes detectados
- Diversidad genÃ©tica
- Tendencias de mutaciones

âœ… **Monitoreo del Cluster**
- MÃ©tricas de Spark (Masters, Workers, Jobs)
- Estado de HDFS (DataNodes, Storage)
- Rendimiento de Executors

---

## ğŸ—ï¸ Arquitectura del Proyecto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PRODUCER (producer/)                     â”‚
â”‚  - family_generator.py: Genera familias genÃ©ticas           â”‚
â”‚  - producer.py: EnvÃ­a datos a Kafka                         â”‚
â”‚  - streaming_manager.py: Gestiona el flujo                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ [KAFKA TOPICS]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CONSUMER (cosumer/)                         â”‚
â”‚  - spark_consumer.py: Consume desde Kafka                   â”‚
â”‚  - Procesa datos genÃ³micos en Spark                         â”‚
â”‚  - Almacena en HDFS                                         â”‚
â”‚  - EnvÃ­a mÃ©tricas al Dashboard                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ [REST API]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DASHBOARD (cosumer/dashboard/)                     â”‚
â”‚  - dashboard_advanced.py: Backend Flask                     â”‚
â”‚  - dashboard.js: GrÃ¡ficos interactivos                      â”‚
â”‚  - index.html: UI moderna                                   â”‚
â”‚  - VisualizaciÃ³n de mÃ©tricas en tiempo real                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ GuÃ­a de Inicio RÃ¡pido

### Requisitos Previos

- **Docker** y **Docker Compose** instalados
- MÃ­nimo **8GB RAM** para el cluster Spark
- Datos genÃ³micos en `producer/data/archive-2/` (5 archivos CSV)

### 1ï¸âƒ£ Preparar Datos

Coloca los archivos genÃ³micos en `producer/data/archive-2/`:
```
producer/data/archive-2/
â”œâ”€â”€ Father Genome.csv
â”œâ”€â”€ Mother Genome.csv
â”œâ”€â”€ Child 1 Genome.csv
â”œâ”€â”€ Child 2 Genome.csv
â””â”€â”€ Child 3 Genome.csv
```

**Dataset**: [Family Genome Dataset - Kaggle](https://www.kaggle.com/datasets/zusmani/family-genome-dataset)

### 2ï¸âƒ£ Desplegar con Docker

```bash
git clone https://github.com/ALbertE03/PGVD.git

```bash
# Iniciar todos los servicios
./start.sh

# Monitorear logs en tiempo real
docker-compose logs -f

# Ver estado de servicios
docker-compose ps
```

### 3ï¸âƒ£ Acceder al Dashboard

```
http://localhost:5000
```

**NavegaciÃ³n del Dashboard:**
- ğŸ–¥ï¸ **Cluster Metrics**: Estado de Spark, HDFS y Jobs
- ğŸ§¬ **Genetic Streaming**: MÃ©tricas avanzadas de datos genÃ³micos
- ğŸ“Š **Data Analysis**: EstadÃ­sticas de procesamiento

### 4ï¸âƒ£ Detener Servicios

```bash
./stop.sh
```

---

## ğŸ“ Estructura del Proyecto

```
PGVD/
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ start.sh                           # Script de inicio
â”œâ”€â”€ stop.sh                            # Script de parada
â”‚
â”œâ”€â”€ producer/                          # Ingesta de datos
â”‚   â”œâ”€â”€ producer.py                    # EnvÃ­a datos a Kafka
â”‚   â”œâ”€â”€ family_generator.py            # Generador de datos genÃ³micos
â”‚   â”œâ”€â”€ streaming_manager.py           # Gestor de flujos
â”‚   â”œâ”€â”€ config.py                      # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ requirements.txt               # Dependencias Python
â”‚   â”œâ”€â”€ Dockerfile                     # Imagen Docker
â”‚   â”œâ”€â”€ docker-compose.yml             # OrquestaciÃ³n
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ archive-2/                 # Datos genÃ³micos (CSV)
â”‚
â”œâ”€â”€ cosumer/                           # Procesamiento y dashboard
â”‚   â”œâ”€â”€ spark_consumer.py              # Consumer Spark
â”‚   â”œâ”€â”€ requirements.txt               # Dependencias Python
â”‚   â”œâ”€â”€ requirements_dashboard.txt     # Deps del dashboard
â”‚   â”œâ”€â”€ entrypoint.sh                  # Script de inicio
â”‚   â”œâ”€â”€ docker-compose.yml             # OrquestaciÃ³n
â”‚   â”œâ”€â”€ dockerfile                     # Imagen base
â”‚   â”œâ”€â”€ Dockerfile.driver              # Spark Driver
â”‚   â”œâ”€â”€ Dockerfile.master              # Spark Master
â”‚   â”œâ”€â”€ Dockerfile.worker              # Spark Worker
â”‚   â”œâ”€â”€ Dockerfile.dashboard           # Dashboard Flask
â”‚   â”œâ”€â”€ driver-entrypoint.sh           # Inicio del driver
â”‚   â”œâ”€â”€ worker-entrypoint.sh           # Inicio del worker
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ dashboard_advanced.py      # Backend Flask (NEW)
â”‚   â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”‚   â””â”€â”€ dashboard.js           # GrÃ¡ficos avanzados (UPDATED)
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚       â””â”€â”€ index.html             # UI moderna (UPDATED)
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ data_models.py             # Modelos de datos
â”‚
â”œâ”€â”€ informe/
â”‚   â””â”€â”€ informe_pgvd.tex               # DocumentaciÃ³n acadÃ©mica
â”‚
â””â”€â”€ photos/                            # Capturas de pantalla
```

---

## ğŸ› ï¸ Scripts de Control

### `start.sh` - Inicia todos los servicios

```bash
./start.sh
```

**QuÃ© hace:**
1. Construye imÃ¡genes Docker
2. Inicia Producer (Kafka, Zookeeper)
3. Inicia Consumer (Spark, HDFS, Dashboard)
4. Inicia generador de datos
5. Monitorea logs en tiempo real

### `stop.sh` - Detiene todos los servicios

```bash
./stop.sh
```

**QuÃ© hace:**
1. Detiene y elimina contenedores
2. Elimina volÃºmenes (opcional)
3. Limpia recursos de Docker

---

## ğŸ”Œ Servicios y Puertos

### Producer (Puerto 9092)
- **Kafka Broker**: `kafka:9092`
- **Zookeeper**: `zookeeper:2181`
- **Jupyter/Generador**: `http://localhost:8888`

### Consumer - Cluster Spark
- **Spark Master**: `http://spark-master-1:8080`
- **Spark Worker 1**: `http://spark-worker-1:8081`
- **Spark Worker 2**: `http://spark-worker-2:8082`
- **Spark Worker 3**: `http://spark-worker-3:8083`
- **Spark Driver UI**: `http://localhost:4040`

### Consumer - HDFS
- **NameNode**: `http://namenode:9870`
- **DataNode 1**: `http://datanode-1:9864`
- **DataNode 2**: `http://datanode-2:9864`
- **DataNode 3**: `http://datanode-3:9864`

### Dashboard
- **Flask Dashboard**: `http://localhost:5000`
- **API REST**: `http://localhost:5000/api/*`

---

## ğŸ“Š Endpoints de API

### MÃ©tricas de Procesamiento
```
GET /api/stats                    # Conteo de familias procesadas
GET /api/cluster_stats            # Estado del cluster Spark/HDFS
GET /api/processing_history       # Historial de procesamiento
GET /api/task_times               # Tiempos de tareas completadas
```

### MÃ©tricas GenÃ©ticas (NUEVAS âœ¨)
```
GET /api/genetic_metrics          # MÃ©tricas de streaming genÃ©tico
GET /api/genetic_trends           # Tendencias de mutaciones
POST /api/genetic_alert           # Detectar anomalÃ­as genÃ©ticas
```

### MÃ©tricas de Spark
```
GET /api/spark_jobs               # Jobs y executors activos
```

---

## ğŸ“ CÃ³mo Funciona el Streaming GenÃ©tico

### 1. Producer envÃ­a datos a Kafka

```python
# producer.py
kafka_message = {
    "member_type": "fathers",
    "total_records": 100,
    "genetic_data": {
        "variant_type": "SNP",
        "gene": "BRCA1",
        "genotype": "0/1",
        "chromosome": 17,
        "position": 41196312,
        "quality": 99.0
    }
}
```

### 2. Consumer recibe y procesa

```python
# spark_consumer.py
# 1. Consume mensajes de Kafka
# 2. Analiza datos genÃ©ticos
# 3. Calcula mÃ©tricas en ventanas de tiempo
# 4. EnvÃ­a a Dashboard vÃ­a API REST
```

### 3. Dashboard muestra en tiempo real

- **Tasa de MutaciÃ³n**: Mutaciones por segundo en ventana de 60s
- **DistribuciÃ³n de Genotipos**: Dominante/Recesivo/Heterocigoto
- **Top Genes**: 5 genes mÃ¡s frecuentes
- **Top Variantes**: 5 variantes mÃ¡s comunes
- **AnomalÃ­as**: Desviaciones de tasa esperada

---

## ğŸ” MÃ©tricas Avanzadas Explicadas

### 1ï¸âƒ£ Tasa de MutaciÃ³n
**FÃ³rmula**: NÃºmero de variantes genÃ©ticas / segundos en ventana

```
Ventana: 60 segundos
Si se reciben 45 variantes en 60s â†’ Tasa = 0.75 variantes/seg
```

### 2ï¸âƒ£ OrientaciÃ³n GenÃ©tica

| Genotipo | OrientaciÃ³n | DescripciÃ³n |
|----------|-------------|------------|
| 0/0 | Recesivo | Dos alelos recesivos |
| 0/1 | Heterocigoto | Un alelo de cada tipo |
| 1/1 | Dominante | Dos alelos dominantes |

### 3ï¸âƒ£ DetecciÃ³n de AnomalÃ­as

```
AnomalÃ­a detectada si:
|Tasa actual - Tasa esperada| > 2.5Ïƒ (desviaciones estÃ¡ndar)
```

### 4ï¸âƒ£ Diversidad GenÃ©tica

```
Diversidad = NÃºmero de genes Ãºnicos / Total de variantes
Rango: 0-1 (1 = mÃ¡xima diversidad)
```

---

## ğŸ› Troubleshooting

### âŒ "Connection refused" en Kafka

```bash
# Verificar que Kafka estÃ¡ corriendo
docker-compose -f producer/docker-compose.yml ps

# Reiniciar
docker-compose -f producer/docker-compose.yml restart kafka zookeeper
```

### âŒ "No space left on device"

```bash
# Limpiar imÃ¡genes y volÃºmenes
docker system prune -a --volumes
./start.sh
```

### âŒ Dashboard no carga grÃ¡ficos

```bash
# Verificar que Flask estÃ¡ corriendo
docker-compose -f cosumer/docker-compose.yml ps

# Ver logs
docker-compose -f cosumer/docker-compose.yml logs dashboard
```

### âŒ Spark sin workers conectados

```bash
# Reiniciar cluster Spark
docker-compose -f cosumer/docker-compose.yml restart spark-master-1
docker-compose -f cosumer/docker-compose.yml restart spark-worker-1 spark-worker-2 spark-worker-3
```

---

## ğŸ“ˆ Ejemplos de Consultas

### Obtener todas las mÃ©tricas genÃ©ticas

```bash
curl http://localhost:5000/api/genetic_metrics
```

**Respuesta:**
```json
{
  "window_size": 156,
  "mutation_rate": 0.0234,
  "mutation_rate_percent": 2.34,
  "genotype_distribution": {
    "dominant": 42,
    "recessive": 35,
    "heterozygous": 79
  },
  "top_genes": [
    {"gene": "BRCA1", "count": 23},
    {"gene": "TP53", "count": 18}
  ],
  "anomaly_count": 0
}
```

### Obtener tendencias

```bash
curl http://localhost:5000/api/genetic_trends
```

**Respuesta:**
```json
{
  "current_mutation_rate": 0.0234,
  "rate_change_percent": 5.2,
  "trend_direction": "up",
  "genotype_percentages": {
    "dominant": 26.92,
    "recessive": 22.44,
    "heterozygous": 50.64
  },
  "genetic_diversity": 0.45,
  "anomaly_rate": 0.0
}
```

### Detectar anomalÃ­a

```bash
curl -X POST http://localhost:5000/api/genetic_alert \
  -H "Content-Type: application/json" \
  -d '{"anomaly_threshold": 2.5}'
```

---

## ğŸ¯ JustificaciÃ³n del Uso de Streaming

âœ… **Â¿Por quÃ© Apache Kafka?**
- Ingesta de datos genÃ³micos en tiempo real (no batch)
- Tolerancia a fallos con replicaciÃ³n
- Escalabilidad horizontal

âœ… **Â¿Por quÃ© Apache Spark?**
- Procesamiento distribuido de ventanas de tiempo
- CÃ¡lculo eficiente de agregaciones
- IntegraciÃ³n con HDFS y Kafka

âœ… **Â¿Por quÃ© HDFS?**
- Almacenamiento distribuido de datasets genÃ³micos
- Alta disponibilidad (replicaciÃ³n 3x)
- Acceso paralelo desde Spark

âœ… **Â¿Por quÃ© Dashboard en tiempo real?**
- Monitoreo instantÃ¡neo de tasa de mutaciÃ³n
- DetecciÃ³n de anomalÃ­as genÃ©ticas
- AnÃ¡lisis de tendencias en directo

---

## ğŸ“š Referencias

- [Apache Spark Documentation](https://spark.apache.org/docs/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache HDFS Architecture](https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [Family Genome Dataset - Kaggle](https://www.kaggle.com/datasets/zusmani/family-genome-dataset)

---
