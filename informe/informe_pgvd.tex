\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{fancyhdr}
\usepackage{array}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{listings}
\usetikzlibrary{arrows.meta, positioning, shapes, backgrounds}

\lstset{
	language=Python,
	basicstyle=\ttfamily\small,
	breaklines=true,
	keywordstyle=\color{blue},
	commentstyle=\color{gray},
	stringstyle=\color{red},
	breakatwhitespace=true
}

\geometry{margin=2.5cm}
\setlength{\headheight}{15pt}
\pagestyle{fancy}
\fancyhf{}
\rhead{\small PGVD - Procesamiento de Grandes Volúmenes de Datos}
\cfoot{\thepage}

\begin{document}
	
	\begin{titlepage}
		\centering
		\vspace*{-1cm}
    		\includegraphics[width=4cm]{../photos/matcom.jpeg}
    	\vspace{1cm}

		{\scshape\LARGE Universidad de La Habana \par}
		\vspace{1cm}
		{\Large Facultad de Matemática y Computación \par}
		{\Large Procesamiento de Grandes Volúmenes de Datos \par}
		\vspace{2.5cm}
		{\Huge \bfseries Informe Técnico del Proyecto \par}
		\vspace{0.5cm}
		{\LARGE \textbf{Sistema Distribuido de Generación y Procesamiento de Datos Genómicos Sintéticos} \par}
		\vspace{2cm}
		{\large \textbf{Integrantes:} \par}
		\vspace{0.5cm}
		\begin{tabular}{rl}
			\textbf{Alberto E. Marichal Fonseca} & -- Ciencia de Datos \\[4pt]
			\textbf{Jabel Resendiz Aguirre} & -- Ciencia de la Computación \\
		\end{tabular}
		\vfill
		{\large 14 de Diciembre 2025 \par}
	\end{titlepage}
	
	\onehalfspacing
	
	\tableofcontents
	\newpage
	
	\section{Descripción del proyecto}
	
	El presente proyecto implementa un \textbf{sistema distribuido} para la generación, transmisión, almacenamiento y análisis de datos genómicos sintéticos en tiempo real. Su objetivo central es \textbf{simular un flujo continuo de información genética} de familias humanas, enfocándose en los \textbf{Single Nucleotide Polymorphisms (SNPs)}, para evaluar el rendimiento de una infraestructura distribuida basada en Apache Kafka y Hadoop HDFS.
	
	Esta iniciativa demuestra principios fundamentales del procesamiento de grandes volúmenes de datos en un contexto de bioinformática, combinando generación de datos sintéticos, streaming en tiempo real, almacenamiento distribuido y análisis avanzado.
	
	\subsection*{1. ¿Qué se pretende lograr? - Objetivo Central}
	
	El objetivo central del proyecto es:
	
	\begin{quote}
		\textbf{\textit{``Diseñar e implementar una plataforma distribuida de streaming para procesar y analizar datos genómicos en tiempo real, demostrando escalabilidad mediante el generación de SNPs sintéticos, su transmisión a través de Kafka, procesamiento distribuido con Spark, almacenamiento persistente en HDFS y visualización de métricas genéticas avanzadas mediante un dashboard interactivo.''}}
	\end{quote}
	
	En términos específicos, el proyecto busca:
	
	\begin{enumerate}
		\item \textbf{Generar} datos genómicos sintéticos realistas basados en un dataset real de familias
		\item \textbf{Transmitir} estos datos en tiempo real mediante un message broker escalable (Kafka)
		\item \textbf{Procesar} grandes volúmenes de SNPs utilizando computación distribuida (Spark Streaming)
		\item \textbf{Detectar} patrones genéticos y anomalías en el análisis en tiempo real
		\item \textbf{Almacenar} la información de manera distribuida y persistente (HDFS)
		\item \textbf{Visualizar} resultados complejos de forma interactiva e intuitiva (Dashboard Flask)
		\item \textbf{Demostrar} tolerancia a fallos, escalabilidad y monitoreo de un cluster distribuido real
	\end{enumerate}
	
	\subsection*{2. Dataset Seleccionado}
	
	\subsubsection*{Identificación del Dataset}
	
	\textbf{Nombre:} Family Genome Dataset (Dataset de Genoma Familiar)
	
	\textbf{Fuente:} Kaggle - Dataset público y gratuito
	
	\textbf{URL:} \url{https://www.kaggle.com/datasets/zusmani/family-genome-dataset}
	
	\textbf{Formato:} Archivos CSV (valores separados por comas)
	
	\subsubsection*{Estructura del Dataset}
	
	El dataset contiene \textbf{5 archivos CSV} que representan los perfiles genómicos de una familia humana completa:
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|l|r|}
			\hline
			\textbf{Archivo} & \textbf{Representa} & \textbf{Registros aprox.} \\
			\hline
			Father Genome.csv & Padre & $\sim$601,802 \\
			\hline
			Mother Genome.csv & Madre & $\sim$601,802 \\
			\hline
			Child 1 Genome.csv & Hijo 1 & $\sim$601.802 \\
			\hline
			Child 2 Genome.csv & Hijo 2 & $\sim$631,983 \\
			\hline
			Child 3 Genome.csv & Hijo 3 & $\sim$631,983 \\
			\hline
			\textbf{TOTAL} & \textbf{Familia completa} & \textbf{$\sim$3,069,372 SNPs} \\
			\hline
		\end{tabular}
		\caption{Composición y volumen del Family Genome Dataset}
	\end{table}
	
	\subsubsection*{Atributos y Columnas}
	
	Cada archivo CSV contiene las siguientes columnas principales que definen completamente un SNP:
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|l|l|l|}
			\hline
			\textbf{Columna} & \textbf{Tipo} & \textbf{Descripción} & \textbf{Ejemplo} \\
			\hline
			RSID & String & ID único del SNP (Reference SNP ID) & rs1801131 \\
			\hline
			Chromosome & String & Cromosoma donde reside el SNP & 1, 2, ..., 22, X, Y, MT \\
			\hline
			Position & Integer & Posición física en el cromosoma (bp) & 232392914 \\
			\hline
			Genotype & String & Variante genética del individuo & AA, Aa, aa \\
			\hline
		\end{tabular}
		\caption{Atributos del Family Genome Dataset}
	\end{table}
	
	\subsubsection*{Características Técnicas del Dataset}
	
	\begin{itemize}
		\item \textbf{Tamaño total:} Aproximadamente 500 MB a 1 GB sin comprimir
		\item \textbf{Rango de cromosomas:} 1-22 (autosomas) + X, Y (cromosomas sexuales) + MT (mitocondrial) = 25 cromosomas
		\item \textbf{Rango de posiciones:} Desde 1 hasta 249,250,621 pares de bases (longitud del genoma humano)
		\item \textbf{Genotipos posibles:} AA (homocigoto), AG (heterocigoto)
		\item \textbf{Cobertura:} SNPs distribuidos a lo largo de todo el genoma humano
		\item \textbf{Ruido:} Datos reales sin ruido artificial - representan secuencias genómicas reales
		\item \textbf{Temporalidad:} Datos estáticos (no cambian con el tiempo)
		\item \textbf{Herencia:} Los hijos contienen combinaciones de genotipos de los padres, reflejando herencia mendeliana
	\end{itemize}

\subsection{3. Justificación del Dataset}

El \textbf{Family Genome Dataset} es la opción óptima para este proyecto por las siguientes razones fundamentadas:

\subsubsection*{A. VOLUMEN - Simulación de Grandes Volúmenes de Datos}

\begin{itemize}
	\item \textbf{Cantidad absoluta:} 5 archivos × 600 mil SNPs = \textbf{3 millones de registros} por ciclo de procesamiento
	
	\item \textbf{Escalabilidad simulada:} El proyecto multiplica este dataset continuamente mediante:
	\begin{itemize}
		\item Generación de múltiples familias sintéticas en paralelo
		\item Envío repetido de datos a través de múltiples threads
		\item Creación de ventanas de tiempo que acumulan datos
	\end{itemize}

	\item \textbf{Almacenamiento:} A este ritmo, el sistema produce:
	\begin{itemize}
		\item 1 hora de ejecución $\rightarrow$ 1 - 2 GB de datos
		\item 24 horas de ejecución $\rightarrow$ 20 - 40 GB de datos
	\end{itemize}
	Esto demuestra verdaderamente la necesidad de un \textbf{sistema distribuido}
	
	\item \textbf{Justificación para Kafka:} Los 3 millones de SNPs iniciales justifican:
	\begin{itemize}
		\item Múltiples consumidores en paralelo
		\item Replicación de topics
		\item Persistencia de mensajes
		\item Particionamiento distribuido
	\end{itemize}
\end{itemize}

\subsubsection*{B. CARACTERÍSTICAS - Estructura de Datos Realista}

\begin{itemize}
	\item \textbf{Atributos significativos:} Los 4 campos (RSID, Chromosome, Position, Genotype) son:
	\begin{itemize}
		\item Suficientemente complejos para justificar análisis avanzado
		\item Realistas dentro del contexto bioinformático
		\item Permiten cálculos genéticos significativos
	\end{itemize}
	
	\item \textbf{Diversidad genética:} El dataset contiene:
	\begin{itemize}
		\item Variantes en todos los 24 cromosomas + mitocondrial.
		\item Distribuidas a lo largo de 3 mil millones de posiciones
		\item Múltiples genotipos para cada SNP (AA, AG, X, Y)
		\item Esto permite detectar patrones no triviales
	\end{itemize}
	
	\item \textbf{Relaciones familiares:} Los 5 miembros de la familia permiten:
	\begin{itemize}
		\item Análisis de herencia genética mendeliana
		\item Detección de inconsistencias biológicas
		\item Comparación entre individuos relacionados
		\item Cálculo de similitud genética
	\end{itemize}
	
	\item \textbf{Complejidad matemática:} El análisis de SNPs requiere:
	\begin{itemize}
		\item Estadística básica (distribuciones, frecuencias)
		\item Cálculos genéticos (ratios de herencia)
		\item Detección de anomalías (desviaciones estadísticas)
		\item Análisis temporal (trends en ventanas)
	\end{itemize}
\end{itemize}

\subsubsection*{C. PERTINENCIA - Alineación con el Objetivo}

\begin{itemize}
	\item \textbf{Generación realista de datos:} El dataset base permite:
	\begin{itemize}
		\item Crear familias sintéticas que mantienen coherencia biológica
		\item Simular herencia mendeliana en tiempo real
		\item Generar variaciones sin perder validez científica
		\item \textbf{Resultado:} El Producer genera datos que parecen reales pero son sintéticos
	\end{itemize}
	
	\item \textbf{Procesamiento con Spark:} La estructura permite:
	\begin{itemize}
		\item Windowing temporal (ventanas de 10 segundos)
		\item Agregación distribuida (por cromosoma, por miembro)
		\item Análisis de streaming (tasa de mutación, distribución de genotipos)
		\item Detección de anomalías (desviaciones en frecuencias)
	\end{itemize}
	
	\item \textbf{Almacenamiento en HDFS:} Los múltiples archivos permiten:
	\begin{itemize}
		\item Particionamiento natural por miembro de familia
		\item Compresión eficiente en Parquet
		\item Análisis histórico (replay de datos)
		\item Recuperación ante fallos
	\end{itemize}
	
	\item \textbf{Visualización significativa:} Los datos genómicos permiten mostrar:
	\begin{itemize}
		\item Métricas biológicamente válidas (tasas de mutación, genotipos)
		\item Gráficos complejos (distribución por cromosoma)
		\item Detección de anomalías en tiempo real
		\item Comparación familiar (similitud genética)
	\end{itemize}
	
	\item \textbf{Justificación académica:} El dataset demuestra:
	\begin{itemize}
		\item Aplicación real de Big Data en bioinformática
		\item Casos de uso prácticos (análisis genético)
		\item Complejidad técnica (streaming distribuido)
		\item Valor agregado (métricas genéticas nuevas)
	\end{itemize}
\end{itemize}

	\section{Arquitectura Propuesta e Implementada}
	
	\subsection*{1. Diagrama del Pipeline de Trabajo}
	
	El sistema implementa un pipeline de procesamiento de datos genómicos sintéticos en \textbf{modo streaming}, que permite generar, transmitir, procesar y analizar SNPs en tiempo real de manera distribuida y tolerante a fallos.
	
	\begin{figure}[h!]
		\centering
		\includegraphics[width=0.95\textwidth]{../photos/Arquitectura.png}
		\caption{Arquitectura general del pipeline de procesamiento de datos genómicos sintéticos en streaming distribuido.}
		\label{fig:architecture}
	\end{figure}
	
	\subsection*{2. Descripción Detallada de Componentes del Pipeline}
	
	El pipeline está compuesto por 5 componentes principales interconectados:
	
	\subsubsection*{Bloque 1: PRODUCER (Generación de Datos)}
	
	\textbf{Función:} Leer datos genómicos reales del Family Genome Dataset, generar familias sintéticas coherentes biológicamente, y transmitir SNPs continuamente a través de Kafka.
	
	\begin{itemize}
		\item \textbf{Entrada:} Archivos CSV (Father, Mother, Children genomes)
		\item \textbf{Procesamiento:} 
		\begin{itemize}
			\item Lectura de ~600K SNPs por individuo
			\item Generación de familias completas
			\item Simulación de herencia mendeliana
			\item Serialización a formato JSON
		\end{itemize}
		\item \textbf{Salida:} Mensajes JSON a 3 topics Kafka (fathers, mothers, children)
		\item \textbf{Escalabilidad:} Multi-threading (1-4 threads paralelos)
		\item \textbf{Justificación:} Crea el volumen de datos necesario para justificar infraestructura distribuida
	\end{itemize}
	
	\subsubsection*{Bloque 2: KAFKA BROKER (Comunicación Distribuida)}
	
	\textbf{Función:} Actuar como intermediario confiable de mensajes, garantizando entrega de SNPs a múltiples consumidores sin pérdida de datos.
	
	\begin{itemize}
		\item \textbf{Entrada:} Mensajes JSON desde Producer
		\item \textbf{Topics:} 3 topics especializados
		\begin{itemize}
			\item \texttt{fathers} - SNPs del padre
			\item \texttt{mothers} - SNPs de la madre
			\item \texttt{children} - SNPs de los hijos
		\end{itemize}
		\item \textbf{Características:}
		\begin{itemize}
			\item Replicación de mensajes
			\item Persistencia en disco
			\item Particionamiento distribuido
			\item Consumer groups configurables
		\end{itemize}
		\item \textbf{Salida:} Mensajes disponibles para múltiples consumidores
		\item \textbf{Latencia:} < 100 ms end-to-end
		\item \textbf{Justificación:} Permite escalabilidad horizontal - múltiples productores y consumidores simultáneos
	\end{itemize}
	
	\subsubsection*{Bloque 3: SPARK STREAMING (Procesamiento Distribuido)}
	
	\textbf{Función:} Consumir datos en tiempo real desde Kafka, realizar análisis genómicos complejos en paralelo, detectar patrones y anomalías.
	
	\begin{itemize}
		\item \textbf{Entrada:} Streams desde 3 topics Kafka
		\item \textbf{Procesamiento Distribuido:}
		\begin{itemize}
			\item Cluster con 1 Master + N Workers
			\item Micro-batching cada 1-10 segundos
			\item Windowing temporal para agregaciones
			\item GROUP BY (cromosoma, miembro, familia)
			\item Agregaciones: COUNT, AVG, MIN, MAX
		\end{itemize}
		\item \textbf{Análisis Genómicos:}
		\begin{itemize}
			\item Cálculo de distribución de genotipos
			\item Tasa de mutación por cromosoma
			\item Detección de cromosomas hotspot
			\item Identificación de anomalías estadísticas
			\item Diversidad genética
		\end{itemize}
		\item \textbf{Salida:} 
		\begin{itemize}
			\item DataFrames procesados a HDFS (Parquet)
			\item Métricas agregadas a Dashboard REST API
			\item Logs de procesamiento
		\end{itemize}
		\item \textbf{Justificación:} Demuestra computación distribuida masivamente paralela, tolerancia a fallos, y procesamiento iterativo
	\end{itemize}
	
	\subsubsection*{Bloque 4: HDFS (Almacenamiento Distribuido Persistente)}
	
	\textbf{Función:} Almacenar datos genómicos procesados de forma distribuida y persistente para análisis históricos y recuperación ante fallos.
	
	\begin{itemize}
		\item \textbf{Entrada:} DataFrames Spark procesados
		\item \textbf{Almacenamiento:}
		\begin{itemize}
			\item Directorio raíz: \texttt{/genomic-data/}
			\item Raw: Datos sin procesar por familia/miembro
			\item Processed: Datos después de transformaciones
			\item Metrics: Resultados de análisis
		\end{itemize}
		\item \textbf{Formato:} Parquet comprimido
		\begin{itemize}
			\item Compresión: Reduce tamaño 60-80\%
			\item Columnular: Optimizado para análisis genómicos
			\item Particionado: Por fecha/hora
		\end{itemize}
		\item \textbf{Características:}
		\begin{itemize}
			\item NameNode: Gestiona metadatos
			\item DataNodes: Almacenan bloques (replicación factor 1)
			\item Recuperación automática ante fallos
		\end{itemize}
		\item \textbf{Capacidad:} 10+ GB en cluster local
		\item \textbf{Justificación:} Demuestra almacenamiento escalable, replicación, y recuperación de desastres
	\end{itemize}
	
	\subsubsection*{Bloque 5: DASHBOARD (Visualización Interactiva)}
	
	\textbf{Función:} Consumir métricas procesadas y presentarlas de forma visual, intuitiva e interactiva en tiempo real.
	
	\begin{itemize}
		\item \textbf{Entrada:} Llamadas REST desde Spark Consumer
		\item \textbf{Componentes:}
		\begin{itemize}
			\item Backend: Flask (Python) - 5 threads
			\item Frontend: HTML5 + CSS3 + JavaScript
			\item Gráficos: Chart.js
			\item Layout: Bootstrap responsive
		\end{itemize}
		\item \textbf{Métricas Mostradas:}
		\begin{itemize}
			\item Familias procesadas en tiempo real
			\item Distribución de genotipos
			\item Top cromosomas y genes
			\item Anomalías detectadas
			\item Estado del cluster Spark
			\item Almacenamiento HDFS utilizado
		\end{itemize}
		\item \textbf{Actualización:} Cada 3 y 5 segundos
		\item \textbf{Acceso:} \url{http://localhost:5000}
		\item \textbf{Justificación:} Demuestra capacidad de decisión en tiempo real basada en datos Big Data
	\end{itemize}
	
	\subsection*{3. Enfoque: Streaming vs Batch vs Hibrido}
	
	El proyecto adopta un enfoque \textbf{STREAMING PURO} por las siguientes razones técnicas:
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|l|l|l|}
			\hline
			\textbf{Aspecto} & \textbf{Batch} & \textbf{Streaming} & \textbf{Elegido} \\
			\hline
			Latencia & 1-24 horas & < 10 segundos & \textbf{Streaming} \\
			\hline
			Actualización & Periódica & Continua & \textbf{Streaming} \\
			\hline
			Escalabilidad & Limitada & Horizontal & \textbf{Streaming} \\
			\hline
			Complejidad & Baja & Media & Acceptable \\
			\hline
			Monitoreo & Offline & Real-time & \textbf{Streaming} \\
			\hline
			Caso de Uso & Reportes & Decisiones instantáneas & \textbf{Streaming} \\
			\hline
		\end{tabular}
		\caption{Comparativa: Batch vs Streaming vs Hybrid}
	\end{table}
	
	\textbf{Justificación del Streaming:}
	\begin{enumerate}
		\item El análisis genómico requiere detección inmediata de anomalías
		\item La visualización debe mostrar tendencias en tiempo real
		\item El procesamiento continuo justifica un cluster distribuido
		\item El flujo continuo de datos requiere tolerancia a fallos
		\item Los micro-batches permiten análisis incremental
	\end{enumerate}

	\subsection*{4. Tecnologías Utilizadas y Justificación}
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|l|l|}
			\hline
			\textbf{Tecnología} & \textbf{Versión} & \textbf{Rol en el Pipeline} \\
			\hline
			Apache Kafka & 3.x & Message Broker en tiempo real \\
			\hline
			Apache Spark & 3.x & Procesamiento distribuido streaming \\
			\hline
			Apache Hadoop HDFS & 3.2.1 & Almacenamiento distribuido persistente \\
			\hline
			Python & 3.9+ & Programación Producer, Consumer, Dashboard \\
			\hline
			Flask & 2.x & Backend web para visualización \\
			\hline
			Docker Compose & 1.29+ & Orquestación de contenedores \\
			\hline
		\end{tabular}
		\caption{Stack tecnológico del proyecto}
	\end{table}
	
	\section*{Metodología de Procesamiento - Pipeline de Transformación de Datos}
	
	El procesamiento sigue estos pasos:
	
	\begin{enumerate}
		\item \textbf{Ingesta (Producer):}
		\begin{itemize}
			\item Lectura de CSV genómicos
			\item Generación de familias sintéticas
			\item Serialización JSON
			\item Envío a Kafka (3 threads paralelos)
		\end{itemize}
		
		\item \textbf{Streaming (Spark Consumer):}
		\begin{itemize}
			\item Suscripción a 3 topics Kafka
			\item Deserialization y schema validation
			\item Windowing (10 segundos tumbling)
			\item Aggregations: COUNT, AVG, GROUP BY
		\end{itemize}
		
		\item \textbf{Análisis Genético:}
		\begin{itemize}
			\item Cálculo de distribución genotípica
			\item Determinación de cromosomas más frecuentes
			\item Detección de posiciones "hotspot"
			\item Cálculo de tasa de mutación
			\item Identificación de anomalías estadísticas
		\end{itemize}
		
		\item \textbf{Persistencia (HDFS):}
		\begin{itemize}
			\item Escritura en formato Parquet comprimido
			\item Particionamiento por fecha/hora
			\item Replicación factor 1 (configurable)
		\end{itemize}
		
		\item \textbf{Visualización (Dashboard):}
		\begin{itemize}
			\item REST API desde Spark Consumer
			\item Almacenamiento en memoria (sliding window)
			\item Actualización cada 2 segundos
			\item Renderizado de gráficos Chart.js
		\end{itemize}
	\end{enumerate}
	
	\subsection*{Algoritmos de Análisis}
	
	\paragraph{Cálculo de Distribución Genotípica}
	
	Para cada ventana de tiempo, se cuenta la ocurrencia de cada genotipo:
	
	\begin{itemize}
		\item Homocigoto (AA): mismo alelo en ambas copias
		\item Heterocigoto (AG): diferente alelo de cada tipo
	\end{itemize}
	
	Se calcula: $Proporcion = \frac{Count_{genotipo}}{Total_{SNPs}}$
	
	\paragraph{Tasa de Mutación}
	
	Se calcula por cromosoma como:
	
	$$MutationRate = \frac{SNPs\_variantes}{Total\_SNPs\_cromosoma}$$
	
	\paragraph{Detección de Anomalías}
	
	Una anomalía se detecta cuando:
	
	$$|Valor - Media| > 3 \times \sigma$$
	
	Donde $\sigma$ es la desviación estándar de la métrica en las últimas 50 ventanas.

	\section{Análisis de Rendimiento del Cluster}
	
	\subsection*{Arquitectura del Cluster Spark}
	
	El cluster de procesamiento distribuido está compuesto por:
	
	\begin{itemize}
		\item \textbf{1 Spark Master:} Orquestador central con 4 cores y 4GB de memoria
		\item \textbf{N Spark Workers:} Workers escalables con 4 cores y 4GB de memoria cada uno
		\item \textbf{Zookeeper:} Coordinador para High Availability (HA)
	\end{itemize}
	
	\subsection*{Métricas del Cluster}
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|l|l|}
			\hline
			\textbf{Componente} & \textbf{Métrica} & \textbf{Estado/Valor} \\
			\hline
			Master & Cores disponibles & 4 \\
			\hline
			Master & Memoria total & 4 GB \\
			\hline
			Workers & Cantidad activos & 2-3 (configurable) \\
			\hline
			Workers & Cores/worker & 4 \\
			\hline
			Workers & Memoria/worker & 4 GB \\
			\hline
			Executores & Número total & 8-12 \\
			\hline
			Tasks & Máx simultáneas & 12-16 \\
			\hline
			Scheduling & Modo & FAIR (equitativo) \\
			\hline
		\end{tabular}
		\caption{Configuración del cluster Spark}
	\end{table}
	
	\subsection*{Tolerancia a Fallos Implementada}
	
	\begin{itemize}
		\item \textbf{Task Retries:} Hasta 20 intentos de reejecutación ante fallos
		
		\item \textbf{Write Ahead Logs:} Habilitados en HDFS para recuperación ante crashes
		
		\item \textbf{Checkpointing:} Guardado periódico del estado del streaming
		
		\item \textbf{Heartbeat:} 30 segundos para detectar ejecutores desconectados
		
		\item \textbf{Timeouts extendidos:} 600 segundos para tolerancia a latencias de red
		
		\item \textbf{Backpressure:} Control adaptativo de flujo para evitar sobrecarga
	\end{itemize}
	
	\subsection*{Monitoreo y Observabilidad}
	
	El sistema proporciona múltiples interfaces para monitoreo:
	
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|l|l|}
			\hline
			\textbf{Componente} & \textbf{URL/Puerto} & \textbf{Información} \\
			\hline
			Spark Master UI & http://localhost:8080 & Jobs, stages, executores \\
			\hline
			Spark Worker UI & http://localhost:8081+ & Recursos, tasks \\
			\hline
			HDFS NameNode & http://localhost:9870 & Metadatos, bloques \\
			\hline
			HDFS DataNode & http://localhost:9864 & Storage, replicación \\
			\hline
			Dashboard & http://localhost:5000 & Métricas genéticas \\
			\hline
		\end{tabular}
		\caption{Interfaces de monitoreo disponibles}
	\end{table}
	
	
	\section*{Análisis de Resultados}
	
	\subsubsection*{Métricas de Procesamiento}
	\begin{table}[h]
		\centering
		\begin{tabular}{|l|r|l|}
			\hline
			\textbf{Métrica} & \textbf{Valor} & \textbf{Observaciones} \\
			\hline
			SNPs/segundo & 50,000 - 200,000 & Escalable con NUM\_THREADS \\
			\hline
			Mensajes Kafka/sec & 50 - 100 & Dependiente del batch size \\
			\hline
			Latencia Kafka & < 100 ms & Comunicación intra-contenedores \\
			\hline
			Tiempo procesamiento/batch & 1 - 3 segundos & Windowed aggregations \\
			\hline
			SNPs procesados/batch & 500K - 1M & Según ventana temporal \\
			\hline
			Throughput HDFS & 50 - 100 MB/s & Escritura Parquet comprimido \\
			\hline
			Latencia Dashboard & 2 - 5 segundos & End-to-end desde Producer \\
			\hline
		\end{tabular}
		\caption{Métricas clave de rendimiento del sistema}
	\end{table}
	
	\subsubsection*{Análisis Genético}
	
	El sistema realiza análisis genómicos complejos incluyendo:
	
	\begin{itemize}
		\item \textbf{Distribución de genotipos:} Clasificación en dominante (AA) y heterocigoto (AG).
		
		\item \textbf{Herencia mendeliana:} Cálculo de patrones hereditarios entre familias.
		
		\item \textbf{Tasa de mutación:} Determinación de frecuencia de variantes genéticas por cromosoma.
		
		\item \textbf{Detección de anomalías:} Identificación de desviaciones estadísticas en distribuciones genéticas.
		
	\end{itemize}
	
	\section{Estado de Implementación y Avances}
	
	Hasta la fecha, el proyecto ha alcanzado los siguientes avances, reflejando la implementación de un prototipo funcional del pipeline de procesamiento de datos genómicos sintéticos en streaming:
	
	\begin{itemize}
		\item \textbf{Infraestructura de streaming y cluster:} Instalación y configuración de Kafka, Spark Streaming, HDFS, incluyendo contenedores Docker para facilitar la reproducibilidad y pruebas locales. HDFS está disponible y configurado para almacenamiento batch, aunque no se utiliza en el flujo principal de streaming.
		\item \textbf{Tópicos y comunicación:} Creación de los tópicos en Kafka y verificación de la comunicación entre el \textit{producer} y el \textit{consumer}.
		\item \textbf{Generador de familias sintéticas:} Desarrollo del módulo que genera familias completas con SNPs simulando datos genómicos reales y envío de los mismos a Kafka en tiempo real.
		\item \textbf{Procesamiento en tiempo real:} Implementación de procesos en Spark Streaming para calcular estadísticas por familia y miembro, sin necesidad de procesamiento batch.
		\item \textbf{Visualización inicial:} Desarrollo de una consola interactiva que consume las estadísticas pre-calculadas desde Kafka y presenta un dashboard en tiempo real.
		\item \textbf{Métricas y monitoreo:} Registro de estadísticas de generación y envío de SNPs, incluyendo número de familias procesadas, SNPs enviados y latencia aproximada.
		\item \textbf{Pruebas de escalabilidad:} Ejecución de pruebas con múltiples hilos de generación para evaluar el comportamiento del pipeline bajo cargas incrementales.
		\item \textbf{Manejo de errores y logs:} Implementación de control de errores y logging en los hilos de streaming para garantizar la estabilidad del prototipo.
	\end{itemize}
	
	Estos avances constituyen un prototipo funcional que valida el enfoque de streaming y permite continuar con la expansión y optimización del pipeline.
	
\end{document}
