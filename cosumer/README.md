# ğŸ§¬ Genomic Data Consumer Dashboard

Dashboard interactivo en tiempo real para consumir y visualizar datos genÃ³micos desde Apache Kafka.

## ğŸš€ CaracterÃ­sticas

- **Consumo en Tiempo Real**: Consume mensajes de Kafka de forma continua y eficiente
- **Interfaz Interactiva**: Dashboard web con Gradio para visualizaciÃ³n de datos
- **Almacenamiento en HDFS**: Persistencia automÃ¡tica de datos en HDFS
- **MÃ©tricas en Vivo**: Seguimiento de tasa de consumo y estadÃ­sticas en tiempo real
- **Visualizaciones DinÃ¡micas**: GrÃ¡ficos interactivos con Plotly

## ğŸ“Š Visualizaciones Disponibles

1. **DistribuciÃ³n por PoblaciÃ³n**: GrÃ¡fico de barras mostrando la distribuciÃ³n de muestras por poblaciÃ³n genÃ©tica
2. **Estado de QC**: GrÃ¡fico circular con el porcentaje de muestras que pasaron/fallaron el control de calidad
3. **DistribuciÃ³n de Coverage**: Histograma de la profundidad de cobertura de secuenciaciÃ³n
4. **Plataformas de SecuenciaciÃ³n**: DistribuciÃ³n de muestras por plataforma tecnolÃ³gica utilizada

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚â”€â”€â”€â”€â”€â–¶â”‚  Consumer   â”‚â”€â”€â”€â”€â”€â–¶â”‚    HDFS      â”‚
â”‚   Broker    â”‚      â”‚  Dashboard  â”‚      â”‚   Storage    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Gradio    â”‚
                     â”‚  Dashboard  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

- `KAFKA_BROKER`: DirecciÃ³n del broker de Kafka (default: `kafka:9092`)
- `KAFKA_TOPIC`: Topic de Kafka a consumir (default: `genomic-data`)
- `HDFS_NAMENODE_URL`: URL del namenode de HDFS (default: `http://namenode:9870`)
- `HDFS_USER`: Usuario para HDFS (default: `root`)

### Componentes del Sistema

- **Kafka Consumer**: Consume mensajes del topic `genomic-data`
- **Buffer en Memoria**: Mantiene los Ãºltimos 10,000 registros en memoria para acceso rÃ¡pido
- **HDFS Writer**: Escribe batches de datos a HDFS cada 60 segundos o cada 100 registros
- **Gradio Dashboard**: Interfaz web en el puerto 7860

## ğŸ³ Despliegue con Docker

### Construir y Ejecutar

```bash
# Desde el directorio cosumer/
docker-compose up -d --build
```

### Ver Logs

```bash
docker logs -f genomic-consumer
```

### Detener

```bash
docker-compose down
```

## ğŸ“ˆ Acceso al Dashboard

Una vez que el contenedor estÃ© ejecutÃ¡ndose, accede al dashboard en:

```
http://localhost:7860
```

## ğŸ“‹ MÃ©tricas Disponibles

El dashboard muestra las siguientes mÃ©tricas en tiempo real:

- **Mensajes Consumidos**: Total de mensajes procesados
- **Buffer en Memoria**: Cantidad de registros actualmente en el buffer
- **Tasa Actual**: Mensajes por segundo (Ãºltimos 5 segundos)
- **Tasa Promedio**: Promedio de mensajes por segundo desde el inicio
- **Tiempo Transcurrido**: Tiempo total de ejecuciÃ³n

## ğŸ”„ Auto-Refresh

El dashboard se actualiza automÃ¡ticamente cada 5 segundos. TambiÃ©n puedes usar el botÃ³n "ğŸ”„ Actualizar Datos" para refrescar manualmente.

## ğŸ“¦ Estructura de Datos

Cada mensaje consumido contiene informaciÃ³n sobre:

- **IdentificaciÃ³n**: Sample ID, Population, Platform
- **MÃ©tricas de Calidad**: QC Status, Coverage, Mapping Quality
- **MÃ©tricas de SecuenciaciÃ³n**: Read Length, GC Content, Duplication Rate
- **Variantes**: SNPs, INDELs, Structural Variants
- **InformaciÃ³n ClÃ­nica**: Gender, Age, Phenotype
- **Datos TÃ©cnicos**: Sequencer ID, Flow Cell, Pipeline Version

## ğŸ› ï¸ Desarrollo

### Estructura de Archivos

```
cosumer/
â”œâ”€â”€ consumer_dashboard.py   # AplicaciÃ³n principal
â”œâ”€â”€ dockerfile              # Imagen Docker
â”œâ”€â”€ docker-compose.yml      # OrquestaciÃ³n de servicios
â”œâ”€â”€ entrypoint.sh          # Script de inicio
â”œâ”€â”€ requirements.txt       # Dependencias Python
â””â”€â”€ README.md             # Este archivo
```

### Dependencias Principales

- `kafka-python`: Cliente de Kafka para Python
- `gradio`: Framework para crear la interfaz web
- `plotly`: Biblioteca de visualizaciÃ³n interactiva
- `pandas`: ManipulaciÃ³n de datos
- `hdfs`: Cliente HDFS para Python

## ğŸ› Troubleshooting

### El consumer no se conecta a Kafka

1. Verifica que el servicio de Kafka estÃ© ejecutÃ¡ndose:
   ```bash
   docker ps | grep kafka
   ```

2. Revisa los logs del consumer:
   ```bash
   docker logs genomic-consumer
   ```

3. Verifica la conectividad de red:
   ```bash
   docker exec genomic-consumer nc -zv kafka 9092
   ```

### No hay datos en el dashboard

1. Verifica que el producer estÃ© ejecutÃ¡ndose y enviando datos
2. Revisa los logs para ver si hay mensajes de error
3. Verifica que el topic de Kafka sea el correcto

### Error de conexiÃ³n a HDFS

El consumer seguirÃ¡ funcionando sin HDFS, pero no persistirÃ¡ los datos. Verifica:

1. Que el namenode de HDFS estÃ© ejecutÃ¡ndose
2. Que la URL del namenode sea correcta
3. Los logs para mensajes de advertencia especÃ­ficos

## ğŸ“ Notas

- El buffer en memoria es circular con capacidad para 10,000 registros
- Los datos se escriben a HDFS en batches para optimizar el rendimiento
- El dashboard usa auto-refresh para mantener los datos actualizados
- El consumer usa `latest` offset por defecto (solo mensajes nuevos)

## ğŸ¤ IntegraciÃ³n con el Ecosistema

Este consumer estÃ¡ diseÃ±ado para trabajar con:

- **Producer**: Genera datos genÃ³micos sintÃ©ticos y los envÃ­a a Kafka
- **Kafka**: Broker de mensajerÃ­a para streaming de datos
- **HDFS**: Sistema de archivos distribuido para almacenamiento persistente
- **Hadoop/YARN**: Procesamiento distribuido de datos (futuro)

## ğŸ“„ Licencia

Este proyecto es parte del sistema PGVD (Processing Genomic Variant Data).
